{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression task - Diamond price training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 7)\n",
      "[[  326.]\n",
      " [  326.]\n",
      " [  327.]\n",
      " ..., \n",
      " [ 2757.]\n",
      " [ 2757.]\n",
      " [ 2757.]]\n"
     ]
    }
   ],
   "source": [
    "# columns 1, 5, 6, 8, 9, 10 have numerical variables\n",
    "# column 7 contains the target: diamond price\n",
    "diamonds_data = np.genfromtxt('diamonds.csv', delimiter=\",\", skip_header=1,\n",
    "                       usecols=(1, 5, 6, 8, 9, 10, 7))\n",
    "\n",
    "print(diamonds_data.shape)\n",
    "print(diamonds_data[:, np.newaxis, -1]) # target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature and target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diamonds_data[:, 0:-1]\n",
    "features = np.insert(features, 0, 1, axis=1)\n",
    "\n",
    "target = diamonds_data[:, np.newaxis, -1]\n",
    "\n",
    "m, n = features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "The general form of the cost function is\n",
    "\n",
    "$$\n",
    "h_\\theta\\left(x\\right) = \\theta_0 x_0 + \\theta_1 x_1 +\n",
    "    \\theta_2 x_2 + \\cdots + \\theta_n x_n \n",
    "$$\n",
    "\n",
    "This can be also interpreted as the dot product betweeen the\n",
    "parameters array and the features array\n",
    "\n",
    "$$\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "x_0 && x_1 && x_2 && \\cdots && x_n\n",
    "\\end{bmatrix},~~\n",
    "\\theta =\n",
    "\\begin{bmatrix}\n",
    "\\theta_0 && \\theta_1 && \\theta_2&& \\cdots && \\theta_n\n",
    "\\end{bmatrix},\n",
    "\\\\\n",
    "h_\\theta\\left(x\\right) = \\theta \\cdot x\n",
    "$$\n",
    "\n",
    "This dot product can be calculated with 2 methods in\n",
    "Numpy:\n",
    "\n",
    "```python\n",
    ">>> numpy.dot(parameters, features)\n",
    "...\n",
    ">>> parameters @ features\n",
    "```\n",
    "\n",
    "The later method will be used, since it is cleaner\n",
    "than the former.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "The main formula for the iteration steps in the\n",
    "Gradient Descent algorithm is\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{m}\n",
    "    \\sum_{i=1}^{m}{\\left(h_\\theta\\left(x^{\\left(i\\right)}\\right) -\n",
    "    y^{\\left(i\\right)}\\right) x_j^{\\left(i\\right)}}\n",
    "$$\n",
    "\n",
    "for all $j = 0, 1, ..., n$, where\n",
    "\n",
    "* $i$ is the index of the data example,\n",
    "* $j$ is the index of the parameter,\n",
    "* $m$ is the number of data examples and\n",
    "* $n$ is the number of parameters.\n",
    "\n",
    "We define a loss $k$ between the cost and the target, such that\n",
    "\n",
    "$$\n",
    "k^{\\left(i\\right)} = h_\\theta\\left(x^{\\left(i\\right)}\\right) -\n",
    "    y^{\\left(i\\right)} ~\n",
    "\\implies\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{m}\n",
    "    \\sum_{i=1}^{m}{k^{\\left(i\\right)} ~ x_j^{\\left(i\\right)}}\n",
    "$$\n",
    "\n",
    "Note that the sum\n",
    "$\\sum_{i=1}^{m}{k^{\\left(i\\right)} ~ x_j^{\\left(i\\right)}}$\n",
    "is also a dot product, and we can simplify even more the\n",
    "formula to\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\left(\n",
    "    k \\cdot x_j\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our model, what we want to have as a final result\n",
    "params = np.ones(n)[:, np.newaxis]\n",
    "\n",
    "alpha = 0.0005\n",
    "\n",
    "features_transp = np.transpose(features)\n",
    "\n",
    "step = 0\n",
    "for i in range(100000):\n",
    "\n",
    "    loss = features @ params - target\n",
    "    params = params - alpha / m * (features_transp @ loss)\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(step, end=', ')\n",
    "        step += 1\n",
    "\n",
    "print(\"end of iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal equation\n",
    "\n",
    "$$\n",
    "\\theta = {\\left( X^T X \\right)}^{-1} X^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t = features.transpose()\n",
    "\n",
    "normal_params = np.linalg.inv(features_t @ features) @ features_t @ target\n",
    "\n",
    "print(normal_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
